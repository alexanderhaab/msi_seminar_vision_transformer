{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fJvfY8LznfJ"
      },
      "source": [
        "# Fine-tuning Vision Transformer (ViT) on a Pokémon Dataset\n",
        "\n",
        "This notebook demonstrates how to fine-tune the `ViT-base-patch16-224` model on a custom Pokémon dataset, to classify Pokemons based on their type.\n",
        "\n",
        "This Notebook uses `Hugging Face` and `PyTorch`.\n",
        "\n",
        "**Dataset:** [JJMack/pokemon-classification-gen1-9](https://huggingface.co/datasets/JJMack/pokemon-classification-gen1-9)\n",
        "\n",
        "**Model:** [ViT-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224)\n",
        "\n",
        "\n",
        "The code in this notebook is inspired by the article: <br>\n",
        "\"[Fine-tuning a Vision Transformer (ViT) Model With a Custom Dataset](https://medium.com/@imabhi1216/fine-tuning-a-vision-transformer-vit-model-with-a-custom-dataset-37840e4e9268)\".\n",
        "All image rights are reserved by Nintendo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O14kiZ6H9LVp"
      },
      "outputs": [],
      "source": [
        "# Get information about the accelerators\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available.\")\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of GPUs: {num_gpus}\")\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"Memory Allocated: {torch.cuda.memory_allocated(i)} bytes\")\n",
        "        print(f\"Memory Cached: {torch.cuda.memory_reserved(i)} bytes\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUbAfwetE5eQ"
      },
      "source": [
        "## Load Pokemon dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_Ubqraj3D6-b"
      },
      "outputs": [],
      "source": [
        "pip install datasets==2.20.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHLQvBvzFlWP"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "# downloads data from hugging face\n",
        "pokemon_dataset = load_dataset(\"JJMack/pokemon-classification-gen1-9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYEOImrbDfW3"
      },
      "outputs": [],
      "source": [
        "pokemon_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1Z2Ra9VOCdK"
      },
      "outputs": [],
      "source": [
        "pokemon_train_dataset = pokemon_dataset['train']\n",
        "pokemon_validation_dataset = pokemon_dataset['validation']\n",
        "pokemon_test_dataset = pokemon_dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S6s92unNMxk"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "type_one_counter = Counter(pokemon_train_dataset['Type 1'])\n",
        "print(f'Type 1: {len(list(type_one_counter.keys()))}')\n",
        "print(type_one_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siwK2gP9-g2w"
      },
      "outputs": [],
      "source": [
        "# See Some examples\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_samples(ds,rows,cols):\n",
        "    samples = ds.shuffle().select(np.arange(rows*cols)) # selecting random images\n",
        "    fig = plt.figure(figsize=(cols*4,rows*4))\n",
        "    # plotting\n",
        "    for i in range(rows*cols):\n",
        "        img = samples[i]['image_data']\n",
        "        label = samples[i]['label']\n",
        "        name = samples[i]['name']\n",
        "        generation = samples[i]['generation']\n",
        "        type_one = samples[i]['Type 1']\n",
        "        type_two = samples[i]['Type 2']\n",
        "        shiny = samples[i]['shiny']\n",
        "        fig.add_subplot(rows,cols,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'{name} ({generation}): {type_one}, {type_two}, {shiny}')\n",
        "        plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "959jGgB_ogeC"
      },
      "source": [
        "## Inspecting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yv3c1Cd8-gs7"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "unique_types = list(type_one_counter.keys())\n",
        "\n",
        "for pokemon_type in unique_types:\n",
        "    # Filter the dataset for the current type\n",
        "    type_subset = pokemon_validation_dataset.filter(lambda x: x['Type 1'] == pokemon_type)\n",
        "    show_samples(type_subset, rows=1, cols=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SetoctuTEeIS"
      },
      "source": [
        "## Classify Pokemon by types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMvpi5wUnKOP"
      },
      "source": [
        "### Change Labels from Name to Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqin0paIVfQy"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "type_one_labels = list(Counter(pokemon_train_dataset['Type 1']).keys())\n",
        "type_one_labels.sort()\n",
        "\n",
        "print(str(len(type_one_labels)) + \": \" + str(type_one_labels))\n",
        "\n",
        "\n",
        "\n",
        "label2id, id2label = dict(), dict()\n",
        "\n",
        "for i, label in enumerate(type_one_labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n",
        "\n",
        "print('label2id')\n",
        "print(label2id)\n",
        "\n",
        "print('id2label')\n",
        "print(id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBsJMIbcfRYs"
      },
      "outputs": [],
      "source": [
        "# Function to map Type 1 string labels to integer IDs\n",
        "def map_type1_to_id(examples):\n",
        "    # Ensure 'Type 1' column exists and is not None\n",
        "    if 'Type 1' in examples and examples['Type 1'] is not None:\n",
        "        # Use a list comprehension to map each Type 1 string to its ID\n",
        "        examples[\"label\"] = [label2id[type1] for type1 in examples[\"Type 1\"]]\n",
        "    else:\n",
        "        # Handle cases where 'Type 1' might be missing (though unlikely for this dataset)\n",
        "        examples[\"label\"] = [-1] * len(examples['image_data']) # Assign a placeholder like -1\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Apply the mapping to your datasets\n",
        "pokemon_train_dataset_mapped = pokemon_train_dataset.map(map_type1_to_id, batched=True)\n",
        "pokemon_validation_dataset_mapped = pokemon_validation_dataset.map(map_type1_to_id, batched=True)\n",
        "pokemon_test_dataset_mapped = pokemon_test_dataset.map(map_type1_to_id, batched=True)\n",
        "\n",
        "\n",
        "# Check the updated labels in the dataset (optional)\n",
        "print(\"\\nExample original labels:\", pokemon_train_dataset[0]['Type 1'])\n",
        "print(label2id[pokemon_train_dataset[0]['Type 1']])\n",
        "\n",
        "print(\"\\nExample original labels:\", pokemon_train_dataset[0]['label'])\n",
        "print(\"Example mapped labels:\", pokemon_train_dataset_mapped[0]['label'])\n",
        "\n",
        "pokemon_train_dataset = pokemon_train_dataset_mapped\n",
        "pokemon_validation_dataset = pokemon_validation_dataset_mapped\n",
        "pokemon_test_dataset = pokemon_test_dataset_mapped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWMHbwCLE5Ty"
      },
      "source": [
        "### Init Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V2lcHyEYapx"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTImageProcessor\n",
        "\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvKgz4uObbmX"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    ToTensor,\n",
        "    Resize,\n",
        ")\n",
        "\n",
        "# Get configurations from ViT processor\n",
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "size = processor.size[\"height\"]\n",
        "\n",
        "# Normalizes the image pixels by subtracting the mean and dividing by the std from the pretrained model configurations\n",
        "normalize = Normalize(mean=image_mean, std=image_std)\n",
        "\n",
        "# Compose: Combines a series of image transformations into one pipeline.\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        RandomResizedCrop(size),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        Resize(size),\n",
        "        CenterCrop(size),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "test_transforms = Compose(\n",
        "    [\n",
        "        Resize(size),\n",
        "        CenterCrop(size),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXWwblDkbhuN"
      },
      "outputs": [],
      "source": [
        "def apply_train_transforms(examples):\n",
        "    examples[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in examples[\"image_data\"]]\n",
        "    return examples\n",
        "\n",
        "\n",
        "def apply_val_transforms(examples):\n",
        "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image_data\"]]\n",
        "    return examples\n",
        "\n",
        "\n",
        "def apply_test_transforms(examples):\n",
        "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image_data\"]]\n",
        "    return examples\n",
        "\n",
        "pokemon_train_dataset.set_transform(apply_train_transforms)\n",
        "pokemon_validation_dataset.set_transform(apply_val_transforms)\n",
        "pokemon_test_dataset.set_transform(apply_test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbeGhEoEb1Lv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    # Stacks the pixel values of all examples into a single tensor and collects labels into a tensor\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "# Create a DataLoader for the training dataset, with custom collation and a batch size of 4\n",
        "train_dl = DataLoader(pokemon_train_dataset, collate_fn=collate_fn, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT_aQPYtb5E1"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dl))\n",
        "for k, v in batch.items():\n",
        "    if isinstance(v, torch.Tensor):\n",
        "        print(k, v.shape)\n",
        "\n",
        "# Output\n",
        "# pixel_values torch.Size([4, 3, 224, 224])\n",
        "# labels torch.Size([4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGMAdOBbnkum"
      },
      "source": [
        "### Feed Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weN0IqXOcLQ5"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels = len(type_one_labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpSHXusJdyIR"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir=\"output-models\",\n",
        "  per_device_train_batch_size=16,\n",
        "  eval_strategy=\"steps\",\n",
        "  num_train_epochs=2,\n",
        "  fp16=True,\n",
        "  save_steps=10,\n",
        "  eval_steps=10,\n",
        "  logging_steps=10,\n",
        "  learning_rate=2e-4,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwureKdVd2lX"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    train_args,\n",
        "    train_dataset=pokemon_train_dataset,\n",
        "    eval_dataset=pokemon_validation_dataset,\n",
        "    data_collator=collate_fn,\n",
        "    tokenizer=processor,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ6gegYLJpte"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(pokemon_test_dataset)\n",
        "print(outputs.metrics)\n",
        "\n",
        "# Output\n",
        "# {'test_loss': 0.25027137994766235,\n",
        "# 'test_runtime': 1.3596,\n",
        "# 'test_samples_per_second': 58.842,\n",
        "# 'test_steps_per_second': 7.355}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xflXE2iucwg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_true = outputs.label_ids\n",
        "y_pred = outputs.predictions.argmax(1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=type_one_labels)\n",
        "disp.plot(xticks_rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CjL8dr2E-uI"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuunUIvkE-I2"
      },
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "\n",
        "checkpoint_path = \"/content/MyDrive/MyDrive/checkpoint-1650\"\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "model = ViTForImageClassification.from_pretrained(checkpoint_path)\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ5rVgrtlFf8"
      },
      "source": [
        "## Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FAOyaeTjTDa"
      },
      "outputs": [],
      "source": [
        "def predict_random_image(dataset, model, transforms, id2label):\n",
        "    random_index = random.randint(0, len(dataset) - 1)\n",
        "\n",
        "    image = dataset[random_index]['image_data']\n",
        "    type_one = dataset[random_index]['Type 1']\n",
        "    name = dataset[random_index]['name']\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"{random_index} {name}: {type_one}\")\n",
        "    plt.show()\n",
        "\n",
        "    processed_image = transforms(image.convert(\"RGB\")).unsqueeze(0) # Fügen Sie eine Batch-Dimension hinzu\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    processed_image = processed_image.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(processed_image)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "    predicted_class_name = id2label[str(predicted_class_idx)]\n",
        "\n",
        "    print(f\"Die vorhergesagte Klasse ist: {predicted_class_name}\")\n",
        "\n",
        "# Example usage:\n",
        "# predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx4ZJue3kCdg"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzUrj95Ak09a"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znV3x6dsk2N3"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGgOdJMlk3bA"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK3dY6YFk55F"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fCTsZmyk9i0"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ-7OrECk_i2"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePtqk1_BlBBl"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDe2G3q1lLV-"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3p58HovlMpQ"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHjdpV7hvkFW"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "image = pokemon_dataset['train'][10]['image_data']\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "processed_image = val_transforms(image.convert(\"RGB\")).unsqueeze(0) \n",
        "\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processed_image = processed_image.to(device)\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(processed_image)\n",
        "    logits = outputs.logits\n",
        "\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "predicted_class_name = id2label[str(predicted_class_idx)]\n",
        "\n",
        "print(f\"Die vorhergesagte Klasse ist: {predicted_class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If6ISWfGxcU1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "image = pokemon_dataset['train'][999]['image_data']\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "processed_image = val_transforms(image.convert(\"RGB\")).unsqueeze(0)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processed_image = processed_image.to(device)\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(processed_image)\n",
        "    logits = outputs.logits\n",
        "\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "predicted_class_name = id2label[str(predicted_class_idx)]\n",
        "\n",
        "print(f\"Die vorhergesagte Klasse ist: {predicted_class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3s-rjx1BcD"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS7G1cSD1JBv"
      },
      "outputs": [],
      "source": [
        "predict_random_image(pokemon_dataset['train'], model, val_transforms, id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtpMu3_cyI6m"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "image_path = '/content/drive/MyDrive/proxy-image.png' \n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "image = Image.open(image_path)\n",
        "\n",
        "processed_image = val_transforms(image.convert(\"RGB\")).unsqueeze(0) \n",
        "\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processed_image = processed_image.to(device)\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(processed_image)\n",
        "    logits = outputs.logits\n",
        "\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "predicted_class_name = id2label[str(predicted_class_idx)]\n",
        "\n",
        "print(f\"Die vorhergesagte Klasse ist: {predicted_class_name}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
